{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNJpH6p+mAR3GN2aediAKcv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijMzOn2mrX4Q","executionInfo":{"status":"ok","timestamp":1717565717126,"user_tz":-330,"elapsed":44156,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"d3eceb85-8690-4193-a84c-c8a22e02a6e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/Flow_Chart_Code/images')"],"metadata":{"id":"ET4d9Rperkbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import os\n","from tqdm import tqdm\n","\n","def preprocess_images(input_dir, output_dir, img_size=(1024, 1024)):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for img_name in tqdm(os.listdir(input_dir)):\n","        img_path = os.path.join(input_dir, img_name)\n","        img = cv2.imread(img_path)\n","\n","        if img is None:\n","            print(f\"Failed to load image: {img_path}\")\n","            continue\n","\n","        img_resized = cv2.resize(img, img_size)\n","        cv2.imwrite(os.path.join(output_dir, img_name), img_resized)\n","\n","input_dir = '/content/drive/MyDrive/Flow_Chart_Code/images'\n","output_dir = '/content/drive/MyDrive/Flow_Chart_Code/Pre_P_Images'\n","preprocess_images(input_dir, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JXvog7GsAxq","executionInfo":{"status":"ok","timestamp":1716568921179,"user_tz":-330,"elapsed":367739,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"92d1ba01-5cf3-4f36-94f4-7c373b1ce3b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 620/620 [06:03<00:00,  1.71it/s]\n"]}]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","\n","def update_xml_annotations(xml_dir, output_dir, img_size=(1024, 1024)):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    for xml_file in tqdm(os.listdir(xml_dir)):\n","        xml_path = os.path.join(xml_dir, xml_file)\n","        tree = ET.parse(xml_path)\n","        root = tree.getroot()\n","\n","        size = root.find('size')\n","        original_width = int(size.find('width').text)\n","        original_height = int(size.find('height').text)\n","\n","        for obj in root.iter('object'):\n","            bndbox = obj.find('bndbox')\n","            xmin = int(bndbox.find('xmin').text)\n","            ymin = int(bndbox.find('ymin').text)\n","            xmax = int(bndbox.find('xmax').text)\n","            ymax = int(bndbox.find('ymax').text)\n","\n","            xmin = int(xmin * img_size[0] / original_width)\n","            ymin = int(ymin * img_size[1] / original_height)\n","            xmax = int(xmax * img_size[0] / original_width)\n","            ymax = int(ymax * img_size[1] / original_height)\n","\n","            bndbox.find('xmin').text = str(xmin)\n","            bndbox.find('ymin').text = str(ymin)\n","            bndbox.find('xmax').text = str(xmax)\n","            bndbox.find('ymax').text = str(ymax)\n","\n","        size.find('width').text = str(img_size[0])\n","        size.find('height').text = str(img_size[1])\n","\n","        tree.write(os.path.join(output_dir, xml_file))\n","\n","xml_dir = '/content/drive/MyDrive/Flow_Chart_Code/annots'\n","output_xml_dir = '/content/drive/MyDrive/Flow_Chart_Code/Pre_A_XMLs'\n","update_xml_annotations(xml_dir, output_xml_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F962JyxNsCvv","executionInfo":{"status":"ok","timestamp":1716569122963,"user_tz":-330,"elapsed":201812,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"a5e64c56-cf16-452e-d214-98bbea5e8099"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 601/601 [03:09<00:00,  3.17it/s]\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15iTOs8q2uCb","executionInfo":{"status":"ok","timestamp":1716569183373,"user_tz":-330,"elapsed":60445,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"43d625db-9547-4e26-e7f6-9b0217ca24b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["import os\n","import xml.etree.ElementTree as ET\n","\n","xml_dir = '/content/drive/MyDrive/Flow_Chart_Code/Pre_A_XMLs'\n","\n","def find_unique_labels(xml_dir):\n","    unique_labels = set()\n","    xml_files = os.listdir(xml_dir)\n","\n","    for xml_file in xml_files:\n","        xml_path = os.path.join(xml_dir, xml_file)\n","        tree = ET.parse(xml_path)\n","        root = tree.getroot()\n","\n","        for obj in root.iter('object'):\n","            label = obj.find('name').text\n","            unique_labels.add(label)\n","\n","    return unique_labels\n","\n","unique_labels = find_unique_labels(xml_dir)\n","print(unique_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veM9SQMkjRWG","executionInfo":{"status":"ok","timestamp":1716569187347,"user_tz":-330,"elapsed":3994,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"c750b288-a3b4-471b-94f4-bc93b8a34cf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'process', 'start_end', 'scan', 'print', 'arrow_line_right', 'arrow_line_up', 'decision', 'arrow_line_down', 'arrow_line_left'}\n"]}]},{"cell_type":"code","source":["label_map = {\n","    \"arrow_line_down\": 1,\n","    \"decision\": 2,\n","    \"process\": 3,\n","    \"start_end\": 4,\n","    \"arrow_line_left\": 5,\n","    \"arrow_line_right\": 6,\n","    \"arrow_line_up\":8,\n","    \"print\":9,\n","    \"scan\": 7  # Add all other unique labels you found here\n","}\n"],"metadata":{"id":"DILKN1XqjgBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.transforms import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import xml.etree.ElementTree as ET\n","import cv2\n","import os\n","\n","class FlowchartDataset(Dataset):\n","    def __init__(self, img_dir, xml_dir, label_map, transforms=None):\n","        self.img_dir = img_dir\n","        self.xml_dir = xml_dir\n","        self.transforms = transforms\n","        self.imgs = sorted([img for img in os.listdir(img_dir) if img.endswith('.jpg')])\n","        self.xmls = sorted([xml for xml in os.listdir(xml_dir) if xml.endswith('.xml')])\n","        self.label_map = label_map\n","\n","        # Ensure the dataset length matches by finding common base names\n","        self.imgs = [img for img in self.imgs if img.replace('.jpg', '.xml') in self.xmls]\n","        self.xmls = [xml for xml in self.xmls if xml.replace('.xml', '.jpg') in self.imgs]\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.imgs[idx])\n","        xml_path = os.path.join(self.xml_dir, self.xmls[idx])\n","\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = F.to_tensor(img)\n","\n","        tree = ET.parse(xml_path)\n","        root = tree.getroot()\n","\n","        boxes = []\n","        labels = []\n","        for obj in root.iter('object'):\n","            label = obj.find('name').text\n","            if label not in self.label_map:\n","                continue  # Skip labels not in the label_map\n","            bndbox = obj.find('bndbox')\n","            xmin = int(bndbox.find('xmin').text)\n","            ymin = int(bndbox.find('ymin').text)\n","            xmax = int(bndbox.find('xmax').text)\n","            ymax = int(bndbox.find('ymax').text)\n","            boxes.append([xmin, ymin, xmax, ymax])\n","            labels.append(self.label_map[label])\n","\n","        if len(boxes) == 0:\n","            # Return dummy data in case there are no valid boxes for this image\n","            boxes = [[0, 0, 1, 1]]\n","            labels = [0]  # Background class\n","\n","        target = {}\n","        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n","        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n","\n","        return img, target\n","\n","# Define the label map\n","label_map = {\n","    \"arrow_line_down\": 1,\n","    \"decision\": 2,\n","    \"process\": 3,\n","    \"start_end\": 4,\n","    \"arrow_line_left\": 5,\n","    \"arrow_line_right\": 6,\n","    \"arrow_line_up\":8,\n","    \"print\":9,\n","    \"scan\": 7  # Add all other unique labels you found here\n","}\n","\n","\n","# Load the dataset\n","output_dir = '/content/drive/MyDrive/Flow_Chart_Code/Pre_P_Images'\n","output_xml_dir = '/content/drive/MyDrive/Flow_Chart_Code/Pre_A_XMLs'\n","dataset = FlowchartDataset(output_dir, output_xml_dir, label_map)\n","data_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n","\n","# Load the model pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n","\n","# Get the number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# Replace the pre-trained head with a new one (number of classes is the number of unique labels in your dataset + background)\n","num_classes = len(label_map) + 1  # Include background as class 0\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Train the model\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, targets in data_loader:\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","    lr_scheduler.step()\n","\n","    print(f\"Epoch {epoch}: Loss: {losses.item()}\")\n","\n","# Save the model weights\n","save_path = '/content/drive/MyDrive/Flow_Chart_Code/faster_rcnn_flowchart.pth'\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure the directory exists\n","torch.save(model.state_dict(), save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcLvIcfY2uhg","executionInfo":{"status":"ok","timestamp":1717511431120,"user_tz":-330,"elapsed":1336536,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"3ceacede-c49e-4f6e-cc07-536fa75d7a66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:00<00:00, 186MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0: Loss: 0.5750427842140198\n","Epoch 1: Loss: 0.4788261651992798\n","Epoch 2: Loss: 0.33107757568359375\n","Epoch 3: Loss: 0.2575295567512512\n","Epoch 4: Loss: 0.36668702960014343\n","Epoch 5: Loss: 0.3312632143497467\n","Epoch 6: Loss: 0.2637271583080292\n","Epoch 7: Loss: 0.2664109170436859\n","Epoch 8: Loss: 0.3633718490600586\n","Epoch 9: Loss: 0.3815934658050537\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms.functional as F\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","\n","# Define the correct number of classes used during training\n","num_classes_trained = 10  # Update this to the actual number of classes used during training\n","\n","# Load the pre-trained model\n","model = fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# Replace the pre-trained head with a new one with the same number of classes as used during training\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_trained)\n","\n","# Load the trained model weights\n","model.load_state_dict(torch.load('faster_rcnn_flowchart.pth'))\n","model.eval()\n","\n","# Now modify the head to the desired number of classes for your use case\n","num_classes_current = 8  # Update this to the actual number of classes you need now\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_current)\n"],"metadata":{"id":"YMMHdwul7Mhe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms.functional as F\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# Define the label map\n","label_map = {\n","    \"arrow_line_down\": 1,\n","    \"decision\": 2,\n","    \"process\": 3,\n","    \"start_end\": 4,\n","    \"arrow_line_left\": 5,\n","    \"arrow_line_right\": 6,\n","    \"arrow_line_up\":8,\n","    \"print\":9,\n","    \"scan\": 7  # Add all other unique labels you found here\n","}\n","reverse_label_map = {v: k for k, v in label_map.items()}\n","\n","# Load the pre-trained model\n","num_classes = len(label_map) + 1  # Include background as class 0\n","model = fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n","\n","# Get the number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# Replace the pre-trained head with a new one (number of classes is the number of unique labels in your dataset + background)\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the trained model weights\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Flow_Chart_Code/faster_rcnn_flowchart.pth'))\n","model.eval()\n","\n","# Move model to the device\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","# Preprocess the image\n","def preprocess_image(image_path):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    img_tensor = F.to_tensor(img)\n","    return img_tensor\n","\n","# Postprocess the output\n","def postprocess_output(prediction, threshold=0.5):\n","    boxes = prediction[0]['boxes']\n","    labels = prediction[0]['labels']\n","    scores = prediction[0]['scores']\n","\n","    # Filter out low confidence predictions\n","    boxes = boxes[scores > threshold]\n","    labels = labels[scores > threshold]\n","    scores = scores[scores > threshold]\n","\n","    return boxes, labels, scores\n","\n","# Test the model on a single image\n","image_path = '/content/drive/MyDrive/Given_FlowCharts/System_Generated/4107.jpg'\n","img_tensor = preprocess_image(image_path)\n","img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","\n","# Move the image tensor to the device\n","img_tensor = img_tensor.to(device)\n","\n","# Get predictions\n","with torch.no_grad():\n","    prediction = model(img_tensor)\n","\n","# Postprocess the output\n","boxes, labels, scores = postprocess_output(prediction, threshold=0.5)\n","\n","# Move boxes and labels to the CPU\n","boxes = boxes.cpu()\n","labels = labels.cpu()\n","\n","# Output the shapes with their coordinates\n","def output_shapes_and_coordinates(boxes, labels, reverse_label_map):\n","    shapes = []\n","    for i in range(len(boxes)):\n","        box = boxes[i].numpy()\n","        label = labels[i].item()\n","        shapes.append({\n","            \"shape\": reverse_label_map[label],\n","            \"coordinates\": {\n","                \"xmin\": int(box[0]),\n","                \"ymin\": int(box[1]),\n","                \"xmax\": int(box[2]),\n","                \"ymax\": int(box[3])\n","            }\n","        })\n","    return shapes\n","\n","shapes = output_shapes_and_coordinates(boxes, labels, reverse_label_map)\n","\n","# Print the shapes and their coordinates\n","for shape in shapes:\n","    print(f\"Shape: {shape['shape']}, Coordinates: {shape['coordinates']}\")\n","\n","# Optionally visualize the results\n","def visualize_results(image_path, boxes, labels, reverse_label_map):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    plt.figure(figsize=(12, 12))\n","    plt.imshow(img)\n","    ax = plt.gca()\n","\n","    for i in range(len(boxes)):\n","        box = boxes[i].numpy()\n","        label = labels[i].item()\n","        color = 'r'\n","        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=2, edgecolor=color, facecolor='none')\n","        ax.add_patch(rect)\n","        plt.text(box[0], box[1], reverse_label_map[label], color=color, fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))\n","\n","    plt.show()\n","\n","visualize_results(image_path, boxes, labels, reverse_label_map)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"CUwhZTtHnVsm","executionInfo":{"status":"error","timestamp":1718903668597,"user_tz":-330,"elapsed":17985,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"3136112e-d14c-4111-a52d-39d030a3534e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:02<00:00, 69.4MB/s]\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Flow_Chart_Code/faster_rcnn_flowchart.pth'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-45bdf7fce8cb>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load the trained model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Flow_Chart_Code/faster_rcnn_flowchart.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Flow_Chart_Code/faster_rcnn_flowchart.pth'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qVDMOQho9OVz"},"execution_count":null,"outputs":[]}]}