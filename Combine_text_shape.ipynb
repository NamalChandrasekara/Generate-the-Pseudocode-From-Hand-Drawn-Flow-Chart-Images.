{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LoSV-ffa-n2GCcF9V4IBA07P40bB3kcQ","timestamp":1719336054034}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"uJdVBMOgiYo_","executionInfo":{"status":"error","timestamp":1718945122405,"user_tz":-330,"elapsed":4781,"user":{"displayName":"Namal chandrasekara","userId":"10964545082619073413"}},"outputId":"e790b81b-9e21-4d53-c2b1-23ce6bf8518f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"7qyx_v0UZzKx","executionInfo":{"status":"ok","timestamp":1719334734276,"user_tz":-330,"elapsed":12075,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"5a023761-8876-4991-b4a7-7f85702a2bf9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-307ca211-f871-4d86-86d3-74610a272a97\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-307ca211-f871-4d86-86d3-74610a272a97\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving shape_todya.py to shape_todya.py\n"]}],"source":["from google.colab import files\n","uploaded = files.upload()\n"]},{"cell_type":"code","source":["uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"e0VDavlhaeOi","executionInfo":{"status":"ok","timestamp":1719133331909,"user_tz":-330,"elapsed":14996,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"31855313-1776-41cb-d2f0-145920d5f521"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-11524c95-8523-463f-a476-7313a9a4eea9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-11524c95-8523-463f-a476-7313a9a4eea9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving text_new.py to text_new.py\n"]}]},{"cell_type":"code","source":["# Load the file\n","%run '/content/shape_todya.py'  # Adjust path accordingly\n","\n","# Assuming you have an image path\n","image_path = '/content/Test2.jpg'  # Adjust path accordingly\n","\n","# Call the function\n","ex_shape, ex_coor = detect_shapes(image_path)\n","\n","# Print or use the results|\n","print(\"Detected Shapes:\", ex_shape)\n","print(\"Coordinates for Shapes:\", ex_coor)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NnMK51fan2p","executionInfo":{"status":"ok","timestamp":1719334823897,"user_tz":-330,"elapsed":47175,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"4a82c553-0a91-4ccf-fe96-5a8655af1115"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:01<00:00, 93.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Detected Shapes: ['arrow_line_down', 'arrow_line_down', 'arrow_line_down', 'start_end', 'start_end', 'arrow_line_down', 'decision', 'arrow_line_right', 'scan', 'arrow_line_down', 'arrow_line_right', 'scan', 'scan', 'arrow_line_left', 'arrow_line_down', 'process', 'arrow_line_down']\n","Coordinates for Shapes: [{'xmin': 288, 'ymin': 117, 'xmax': 328, 'ymax': 191}, {'xmin': 227, 'ymin': 834, 'xmax': 259, 'ymax': 897}, {'xmin': 233, 'ymin': 288, 'xmax': 274, 'ymax': 370}, {'xmin': 248, 'ymin': 22, 'xmax': 398, 'ymax': 122}, {'xmin': 181, 'ymin': 889, 'xmax': 369, 'ymax': 1016}, {'xmin': 510, 'ymin': 824, 'xmax': 547, 'ymax': 948}, {'xmin': 106, 'ymin': 348, 'xmax': 393, 'ymax': 550}, {'xmin': 364, 'ymin': 926, 'xmax': 556, 'ymax': 958}, {'xmin': 398, 'ymin': 707, 'xmax': 652, 'ymax': 845}, {'xmin': 265, 'ymin': 541, 'xmax': 304, 'ymax': 718}, {'xmin': 380, 'ymin': 425, 'xmax': 525, 'ymax': 446}, {'xmin': 100, 'ymin': 712, 'xmax': 373, 'ymax': 857}, {'xmin': 126, 'ymin': 179, 'xmax': 477, 'ymax': 304}, {'xmin': 362, 'ymin': 931, 'xmax': 553, 'ymax': 958}, {'xmin': 513, 'ymin': 574, 'xmax': 550, 'ymax': 708}, {'xmin': 144, 'ymin': 184, 'xmax': 446, 'ymax': 302}, {'xmin': 206, 'ymin': 593, 'xmax': 239, 'ymax': 627}]\n"]}]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9L6Z5RKnOnGK","executionInfo":{"status":"ok","timestamp":1717672031254,"user_tz":-330,"elapsed":24198,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"be5b37e7-4523-4fe4-9211-3c4137522124"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["script_code = \"\"\"\n","\n","# Import necessary libraries\n","import os\n","import matplotlib.pyplot as plt\n","import keras_ocr\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","from symspellpy.symspellpy import SymSpell, Verbosity\n","import pkg_resources\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the function to extract text and coordinates\n","def extract_text_and_coordinates(image_path):\n","    class TextClassifier:\n","        def __init__(self):\n","            # Initialize keras-ocr pipeline\n","            self.pipeline = keras_ocr.pipeline.Pipeline()\n","\n","        def __set_image(self, image_path):\n","            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","            blur = cv2.GaussianBlur(image, (5, 5), 0)\n","            _, image = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","            return image\n","\n","        def __get_bbox(self, image_path):\n","            images = keras_ocr.tools.read(image_path)\n","            self.image = images\n","            prediction_groups = self.pipeline.recognize([images])\n","            texts = []\n","            results = []\n","\n","            for ibox in prediction_groups[0]:\n","                box = ibox[1]\n","                texts.append(ibox[0])\n","                xs, ys = set(), set()\n","                for x in box:\n","                    xs.add(x[0])\n","                    ys.add(x[1])\n","                results.append(list(map(int, [min(xs), min(ys), max(xs), max(ys)]))) # ymin, xmin, ymax, xmax\n","\n","            return results, texts\n","\n","        def recognize(self, image_path):\n","            boxes, texts = self.__get_bbox(image_path)\n","            nodes = []\n","\n","            for box, text in zip(boxes, texts):\n","                xmin, ymin, xmax, ymax = box\n","                nodes.append({'text': text, 'coordinate': [xmin, xmax, ymin, ymax]})\n","\n","            return nodes\n","\n","    # Initialize the classifier\n","    classifier = TextClassifier()\n","\n","    # Recognize text in the image\n","    nodes = classifier.recognize(image_path)\n","\n","    # Extract text and coordinates into separate arrays\n","    ex_text = [node['text'] for node in nodes]\n","    ex_co = [node['coordinate'] for node in nodes]\n","\n","    return ex_text, ex_co\n","\n","# Define the function to correct text\n","def correct_text(text_array):\n","    # Initialize SymSpell object\n","    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n","\n","    # Load the dictionary\n","    dictionary_path = pkg_resources.resource_filename(\n","        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n","    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n","\n","    corrected_text_array = []\n","    for text in text_array:\n","        suggestions = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)\n","        if suggestions:\n","            corrected_text_array.append(suggestions[0].term)\n","        else:\n","            corrected_text_array.append(text)\n","    return corrected_text_array\n","\n","# Main function\n","def main(image_path):\n","    # Extract text and coordinates\n","    ex_text, ex_co = extract_text_and_coordinates(image_path)\n","\n","    # Correct the extracted text\n","    cr_text = correct_text(ex_text)\n","\n","    # Print the results\n","    print(\"Extracted Texts:\", ex_text)\n","    print(\"Corrected Texts:\", cr_text)\n","    print(\"Extracted Coordinates:\", ex_co)\n","\n","    # Optionally, display the image with bounding boxes\n","    image = cv2.imread(image_path)\n","    for coord in ex_co:\n","        xmin, xmax, ymin, ymax = coord\n","        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n","        cv2.putText(image, ex_text[ex_co.index(coord)], (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()\n","\n","    return ex_text, cr_text, ex_co\n","\"\"\"\n","\n","# Save the script code to a .py file\n","with open('/content/drive/MyDrive/ocr_script.py', 'w') as f:\n","    f.write(script_code)\n"],"metadata":{"id":"eFwHvlHIRupb","executionInfo":{"status":"ok","timestamp":1719334833240,"user_tz":-330,"elapsed":703,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow keras-ocr opencv-python numpy symspellpy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZoKzMxZQkor","executionInfo":{"status":"ok","timestamp":1719334861966,"user_tz":-330,"elapsed":24561,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"82addae4-bab8-44e5-984a-24d437f76e77"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Collecting keras-ocr\n","  Downloading keras_ocr-0.9.3-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Collecting symspellpy\n","  Downloading symspellpy-6.7.7-py3-none-any.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.6.2)\n","Collecting efficientnet==1.0.0 (from keras-ocr)\n","  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n","Collecting essential_generators (from keras-ocr)\n","  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.53.0)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.4.0)\n","Collecting pyclipper (from keras-ocr)\n","  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (2.0.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.66.4)\n","Collecting validators (from keras-ocr)\n","  Downloading validators-0.28.3-py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras-ocr)\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.19.3)\n","Collecting editdistpy>=0.1.3 (from symspellpy)\n","  Downloading editdistpy-0.1.4.tar.gz (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.11.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (9.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (3.7.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (2.31.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (3.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2024.6.18)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.6.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Building wheels for collected packages: editdistpy\n","  Building wheel for editdistpy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for editdistpy: filename=editdistpy-0.1.4-cp310-cp310-linux_x86_64.whl size=187494 sha256=0537832c94a5e06a36853b29c9794dad30d45fed236ac2ed46ebd6f25974a59d\n","  Stored in directory: /root/.cache/pip/wheels/4c/0f/10/c20d67cd765ee5b3666d759a307241bba0663135d6ee1c0072\n","Successfully built editdistpy\n","Installing collected packages: pyclipper, essential_generators, validators, editdistpy, symspellpy, keras-applications, efficientnet, keras-ocr\n","Successfully installed editdistpy-0.1.4 efficientnet-1.0.0 essential_generators-1.0 keras-applications-1.0.8 keras-ocr-0.9.3 pyclipper-1.3.0.post5 symspellpy-6.7.7 validators-0.28.3\n"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","import os\n","import matplotlib.pyplot as plt\n","import keras_ocr\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","from symspellpy.symspellpy import SymSpell, Verbosity\n","import pkg_resources\n","\n","# Mount Google Drive\n","#drive.mount('/content/drive')\n","\n","class OCRProcessor:\n","    def __init__(self):\n","        # Create a pipeline for OCR processing\n","        self.pipeline = keras_ocr.pipeline.Pipeline()\n","\n","    def __get_bbox(self, image_path):\n","        try:\n","            # Read the image using OpenCV\n","            image = cv2.imread(image_path)\n","            if image is None:\n","                raise ValueError(f\"Image at path {image_path} could not be read.\")\n","\n","            # Convert the image to RGB (keras-ocr expects RGB images)\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","            # Use the OCR pipeline to detect text\n","            images = keras_ocr.tools.read(image_path)\n","            self.image = images\n","            prediction_groups = self.pipeline.recognize([images])\n","\n","            if not prediction_groups or not prediction_groups[0]:\n","                return [], []\n","\n","            # Extract the bounding boxes and text\n","            texts = []\n","            results = []\n","            for text, box in prediction_groups[0]:\n","                texts.append(text)\n","                xs, ys = set(), set()\n","                for x in box:\n","                    xs.add(x[0])\n","                    ys.add(x[1])\n","                results.append(list(map(int, [min(xs), min(ys), max(xs), max(ys)])))  # ymin, xmin, ymax, xmax\n","\n","            return texts, results\n","        except Exception as e:\n","            print(f\"An error occurred in __get_bbox: {e}\")\n","            return [], []\n","\n","    def process_image(self, image_path):\n","        return self.__get_bbox(image_path)\n","\n","# Define the function to correct text\n","def correct_text(text_array):\n","    # Initialize SymSpell object\n","    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n","\n","    # Load the dictionary\n","    dictionary_path = pkg_resources.resource_filename(\n","        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n","    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n","\n","    corrected_text_array = []\n","    for text in text_array:\n","        suggestions = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)\n","        if suggestions:\n","            corrected_text_array.append(suggestions[0].term)\n","        else:\n","            corrected_text_array.append(text)\n","    return corrected_text_array\n","\n","# Main function\n","def main(image_path):\n","    ocr_processor = OCRProcessor()\n","    ex_text, ex_co = ocr_processor.process_image(image_path)\n","    if not ex_text:\n","        print(f\"No text detected in the image at path {image_path}.\")\n","        return [], [], []\n","\n","    # Correct the extracted text\n","    cr_text = correct_text(ex_text)\n","\n","    # Print the results\n","    print(\"Extracted Texts:\", ex_text)\n","    print(\"Corrected Texts:\", cr_text)\n","    print(\"Extracted Coordinates:\", ex_co)\n","\n","    # Optionally, display the image with bounding boxes\n","    # image = cv2.imread(image_path)\n","    # for coord in ex_co:\n","    #     xmin, xmax, ymin, ymax = coord\n","    #     cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n","    #     cv2.putText(image, ex_text[ex_co.index(coord)], (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n","\n","    # plt.figure(figsize=(10, 10))\n","    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    # plt.axis('off')\n","    # #plt.show()\n","\n","    return ex_text, cr_text, ex_co\n","\n","# Example usage (you can update the image path as needed)\n","image_path = '/content/4107.jpg'\n","ex_text, cr_text, ex_co = main(image_path)\n","\n","ex_shape, ex_coor = detect_shapes(image_path)\n","\n","# Print or use the results\n","print(\"Detected Shapes:\", ex_shape)\n","print(\"Coordinates for Shapes:\", ex_coor)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8jjwpjHXvmq","executionInfo":{"status":"ok","timestamp":1719335953433,"user_tz":-330,"elapsed":17845,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"e43cc140-75d1-450f-f889-19c49b4c39e1"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking for /root/.keras-ocr/craft_mlt_25k.h5\n","Looking for /root/.keras-ocr/crnn_kurapan.h5\n","1/1 [==============================] - 7s 7s/step\n","1/1 [==============================] - 4s 4s/step\n","Extracted Texts: ['start', 'input', 'number', 'no', 'ls', 'number', '0', '2e0', 'yes', 'output', 'output', 'even', 'odd', 'end']\n","Corrected Texts: ['start', 'input', 'number', 'no', 'is', 'number', 'a', 'be', 'yes', 'output', 'output', 'even', 'odd', 'end']\n","Extracted Coordinates: [[82, 28, 110, 41], [80, 117, 110, 129], [73, 132, 118, 143], [234, 237, 251, 249], [89, 243, 101, 253], [52, 256, 94, 267], [96, 257, 108, 268], [109, 257, 142, 268], [101, 319, 122, 331], [78, 368, 113, 379], [254, 368, 289, 379], [81, 382, 109, 394], [260, 382, 285, 395], [84, 460, 106, 471]]\n","Detected Shapes: ['start_end', 'start_end', 'arrow_line_down', 'arrow_line_down', 'arrow_line_down', 'arrow_line_down', 'decision', 'process', 'arrow_line_left', 'scan', 'scan', 'arrow_line_down', 'process', 'scan', 'arrow_line_right']\n","Coordinates for Shapes: [{'xmin': 39, 'ymin': 6, 'xmax': 150, 'ymax': 63}, {'xmin': 39, 'ymin': 437, 'xmax': 147, 'ymax': 493}, {'xmin': 88, 'ymin': 410, 'xmax': 102, 'ymax': 439}, {'xmin': 88, 'ymin': 159, 'xmax': 102, 'ymax': 200}, {'xmin': 88, 'ymin': 309, 'xmax': 103, 'ymax': 350}, {'xmin': 88, 'ymin': 59, 'xmax': 102, 'ymax': 100}, {'xmin': 23, 'ymin': 193, 'xmax': 166, 'ymax': 316}, {'xmin': 72, 'ymin': 128, 'xmax': 121, 'ymax': 144}, {'xmin': 146, 'ymin': 459, 'xmax': 269, 'ymax': 471}, {'xmin': 202, 'ymin': 345, 'xmax': 338, 'ymax': 419}, {'xmin': 17, 'ymin': 346, 'xmax': 172, 'ymax': 419}, {'xmin': 263, 'ymin': 258, 'xmax': 278, 'ymax': 353}, {'xmin': 16, 'ymin': 97, 'xmax': 180, 'ymax': 165}, {'xmin': 0, 'ymin': 96, 'xmax': 188, 'ymax': 169}, {'xmin': 161, 'ymin': 248, 'xmax': 274, 'ymax': 260}]\n"]}]},{"cell_type":"code","source":["def map_text_to_shapes(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates):\n","    # Initialize a dictionary to store the texts for each shape\n","    shape_texts = {i: [] for i in range(len(detected_shapes))}\n","\n","    # Helper function to check if a coordinate is inside or near a shape's bounding box\n","    def is_inside_or_near(coord, shape_coord, threshold=10):\n","        x, y, x2, y2 = coord[0], coord[1], coord[2], coord[3]\n","        xmin, ymin, xmax, ymax = shape_coord['xmin'], shape_coord['ymin'], shape_coord['xmax'], shape_coord['ymax']\n","        return (xmin - threshold <= x <= xmax + threshold and\n","                ymin - threshold <= y <= ymax + threshold and\n","                xmin - threshold <= x2 <= xmax + threshold and\n","                ymin - threshold <= y2 <= ymax + threshold)\n","\n","    # Helper function to check if one shape is inside or overlaps significantly with another\n","    def is_significantly_overlapping(shape_coord1, shape_coord2):\n","        xmin1, ymin1, xmax1, ymax1 = shape_coord1['xmin'], shape_coord1['ymin'], shape_coord1['xmax'], shape_coord1['ymax']\n","        xmin2, ymin2, xmax2, ymax2 = shape_coord2['xmin'], shape_coord2['ymin'], shape_coord2['xmax'], shape_coord2['ymax']\n","\n","        # Check if shape_coord1 is completely inside shape_coord2\n","        if (xmin2 <= xmin1 <= xmax2 and ymin2 <= ymin1 <= ymax2 and\n","            xmin2 <= xmax1 <= xmax2 and ymin2 <= ymax1 <= ymax2):\n","            return True\n","\n","        # Check if shape_coord2 is completely inside shape_coord1\n","        if (xmin1 <= xmin2 <= xmax1 and ymin1 <= ymin2 <= ymax1 and\n","            xmin1 <= xmax2 <= xmax1 and ymin1 <= ymax2 <= ymax1):\n","            return True\n","\n","        # Check for significant overlap\n","        overlap_x = max(0, min(xmax1, xmax2) - max(xmin1, xmin2))\n","        overlap_y = max(0, min(ymax1, ymax2) - max(ymin1, ymin2))\n","        area_overlap = overlap_x * overlap_y\n","        area_shape1 = (xmax1 - xmin1) * (ymax1 - ymin1)\n","        area_shape2 = (xmax2 - xmin2) * (ymax2 - ymin2)\n","\n","        # Consider significant if overlap is more than 50% of either shape\n","        return area_overlap / area_shape1 > 0.5 or area_overlap / area_shape2 > 0.5\n","\n","    # Iterate through each text and its coordinates\n","    for text, coord in zip(corrected_texts, extracted_coordinates):\n","        for i, (shape, shape_coord) in enumerate(zip(detected_shapes, shape_coordinates)):\n","            if shape.startswith('arrow_line'):\n","                continue  # Ignore arrow lines\n","            if is_inside_or_near(coord, shape_coord):\n","                shape_texts[i].append(text)\n","                break\n","\n","    # Prepare the final output as a multidimensional array\n","    final_texts_by_shapes = []\n","    for i, shape in enumerate(detected_shapes):\n","        if not shape.startswith('arrow_line'):\n","            final_texts_by_shapes.append([shape, shape_coordinates[i], shape_texts[i]])\n","\n","    # Remove redundant shapes (same or overlapping shapes) but keep one\n","    unique_shapes = []\n","    redundant_indices = set()\n","    for i, (shape_name1, shape_coord1, texts1) in enumerate(final_texts_by_shapes):\n","        if i in redundant_indices:\n","            continue\n","        for j, (shape_name2, shape_coord2, texts2) in enumerate(final_texts_by_shapes):\n","            if i != j and (shape_name1 == 'scan' or shape_name1 == 'process') and (shape_name2 == 'scan' or shape_name2 == 'process'):\n","                if is_significantly_overlapping(shape_coord1, shape_coord2):\n","                    if shape_name1 == 'scan':\n","                        redundant_indices.add(j)  # Prefer scan, mark process as redundant\n","                    else:\n","                        redundant_indices.add(i)  # Prefer process, mark scan as redundant\n","\n","        if i not in redundant_indices:\n","            unique_shapes.append([shape_name1, shape_coord1, texts1])\n","\n","    # Sort unique shapes by their ymin value\n","    unique_shapes.sort(key=lambda x: x[1]['ymin'])\n","\n","    # Rename shapes based on their position and type\n","    process_counter = 1\n","    for i, (shape_name, shape_coord, texts) in enumerate(unique_shapes):\n","        if shape_name == 'start_end':\n","            if i == 0:\n","                unique_shapes[i][0] = 'Start'\n","            elif i == len(unique_shapes) - 1:\n","                unique_shapes[i][0] = 'End'\n","        elif shape_name == 'scan':\n","            unique_shapes[i][0] = f'Process {process_counter}'\n","            process_counter += 1\n","        elif shape_name == 'process':\n","            unique_shapes[i][0] = f'Process {process_counter}'\n","            process_counter += 1\n","\n","    return unique_shapes\n"],"metadata":{"id":"RPzy9dViX7ex","executionInfo":{"status":"ok","timestamp":1719335955756,"user_tz":-330,"elapsed":2,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def print_mapped_texts(mapped_texts):\n","    for shape, coordinates, texts in mapped_texts:\n","        print(f\"Shape: {shape}\")\n","        print(f\"Coordinates: xmin={coordinates['xmin']}, ymin={coordinates['ymin']}, xmax={coordinates['xmax']}, ymax={coordinates['ymax']}\")\n","        if texts:\n","            print(\"Texts:\")\n","            for text in texts:\n","                print(f\" - {text}\")\n","        else:\n","            print(\"Texts: None\")\n","        print('-' * 40)\n","\n","# Get the mapped texts\n","\n","corrected_texts = cr_text\n","extracted_coordinates = ex_co\n","detected_shapes = ex_shape\n","shape_coordinates = ex_coor\n","mapped_texts = map_text_to_shapes(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates)\n","\n","# Print the mapped texts\n","print_mapped_texts(mapped_texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WphkSsfYh1Z","executionInfo":{"status":"ok","timestamp":1719335957376,"user_tz":-330,"elapsed":4,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"cd966fd6-5422-4dc0-9dae-a54fd2454652"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape: Start\n","Coordinates: xmin=39, ymin=6, xmax=150, ymax=63\n","Texts:\n"," - start\n","----------------------------------------\n","Shape: Process 1\n","Coordinates: xmin=0, ymin=96, xmax=188, ymax=169\n","Texts: None\n","----------------------------------------\n","Shape: decision\n","Coordinates: xmin=23, ymin=193, xmax=166, ymax=316\n","Texts:\n"," - is\n"," - number\n"," - a\n"," - be\n","----------------------------------------\n","Shape: Process 2\n","Coordinates: xmin=202, ymin=345, xmax=338, ymax=419\n","Texts:\n"," - output\n"," - odd\n","----------------------------------------\n","Shape: Process 3\n","Coordinates: xmin=17, ymin=346, xmax=172, ymax=419\n","Texts:\n"," - output\n"," - even\n","----------------------------------------\n","Shape: End\n","Coordinates: xmin=39, ymin=437, xmax=147, ymax=493\n","Texts:\n"," - end\n","----------------------------------------\n"]}]},{"cell_type":"code","source":["def get_connected_arrows_and_destinations(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates):\n","    def find_final_destination(arrow_coords, visited_arrows):\n","        \"\"\"\n","        Recursively find the final destination shape for the given arrow coordinates.\n","        \"\"\"\n","        arrow_coords_tuple = tuple(arrow_coords.items())\n","        if arrow_coords_tuple in visited_arrows:\n","            # Avoid revisiting the same arrow\n","            return None, None\n","\n","        visited_arrows.add(arrow_coords_tuple)\n","\n","        for k, shape in enumerate(detected_shapes):\n","            if 'arrow_line' not in shape:\n","                shape_coords = shape_coordinates[k]\n","                shape_xmin = shape_coords['xmin']\n","                shape_ymin = shape_coords['ymin']\n","                shape_xmax = shape_coords['xmax']\n","                shape_ymax = shape_coords['ymax']\n","\n","                # Check if the arrow end coordinates are within the bounds of this shape\n","                if (arrow_coords['xmax'] >= shape_xmin and arrow_coords['xmax'] <= shape_xmax and\n","                    arrow_coords['ymax'] >= shape_ymin and arrow_coords['ymax'] <= shape_ymax):\n","                    return shape, shape_coords\n","\n","        for k, shape in enumerate(detected_shapes):\n","            if 'arrow_line' in shape:\n","                arrow_coords_next = shape_coordinates[k]\n","\n","                # Check if the arrow end coordinates are within the bounds of another arrow\n","                if (arrow_coords['xmax'] >= arrow_coords_next['xmin'] and\n","                    arrow_coords['xmax'] <= arrow_coords_next['xmax'] and\n","                    arrow_coords['ymax'] >= arrow_coords_next['ymin'] and\n","                    arrow_coords['ymax'] <= arrow_coords_next['ymax']):\n","                    return find_final_destination(arrow_coords_next, visited_arrows)\n","        return None, None\n","\n","    def label_arrow(arrow_coords):\n","        \"\"\"\n","        Identify if an arrow is labeled with 'yes' or 'no'.\n","        \"\"\"\n","        for text, coord in zip(corrected_texts, extracted_coordinates):\n","            if text.lower() in ['yes', 'no']:\n","                text_xmin, text_ymin, text_xmax, text_ymax = coord\n","                if (arrow_coords['xmin'] <= text_xmax and arrow_coords['xmax'] >= text_xmin and\n","                    arrow_coords['ymin'] <= text_ymax and arrow_coords['ymax'] >= text_ymin):\n","                    return text.lower()\n","        return None\n","\n","    def find_nearest_processes_below_or_same_level(dec_coords):\n","        \"\"\"\n","        Find the nearest process shapes below or at the same level as the decision block coordinates.\n","        \"\"\"\n","        dec_xmin, dec_ymin, dec_xmax, dec_ymax = dec_coords['xmin'], dec_coords['ymin'], dec_coords['xmax'], dec_coords['ymax']\n","        nearest_processes = []\n","\n","        for i, shape in enumerate(detected_shapes):\n","            if shape.startswith('Process'):\n","                shape_coords = shape_coordinates[i]\n","                shape_ymin = shape_coords['ymin']\n","\n","                # Consider shapes below or at the same level as the decision block\n","                if shape_ymin >= dec_ymin:\n","                    nearest_processes.append((shape, shape_coords))\n","\n","        return sorted(nearest_processes, key=lambda x: x[1]['ymin'])\n","\n","    # Initialize a dictionary to store arrows connected to each decision block and their destinations\n","    decisions_and_arrows_destinations = {}\n","\n","    # Find all decision blocks\n","    decision_indices = [i for i, shape in enumerate(detected_shapes) if shape == 'decision']\n","\n","    if not decision_indices:\n","        raise ValueError(\"No decision blocks found in detected shapes.\")\n","\n","    # Iterate through all decision blocks\n","    for decision_index in decision_indices:\n","        decision_coordinates = shape_coordinates[decision_index]\n","\n","        # Coordinates of the decision block\n","        dec_xmin = decision_coordinates['xmin']\n","        dec_ymin = decision_coordinates['ymin']\n","        dec_xmax = decision_coordinates['xmax']\n","        dec_ymax = decision_coordinates['ymax']\n","\n","        # Initialize a list to store coordinates of connected arrows and their destinations for the current decision block\n","        connected_arrows_destinations = []\n","\n","        # Check each shape for connected arrows\n","        for i, shape in enumerate(detected_shapes):\n","            if 'arrow_line' in shape:\n","                # Get coordinates of the current arrow\n","                arrow_coords = shape_coordinates[i]\n","                arrow_xmin = arrow_coords['xmin']\n","                arrow_ymin = arrow_coords['ymin']\n","                arrow_xmax = arrow_coords['xmax']\n","                arrow_ymax = arrow_coords['ymax']\n","\n","                # Check if the arrow is connected to the decision block\n","                if (arrow_ymin <= dec_ymax and arrow_ymax >= dec_ymin and\n","                    (arrow_xmax >= dec_xmin and arrow_xmin <= dec_xmax)) or \\\n","                   (arrow_xmin <= dec_xmax and arrow_xmax >= dec_xmin and\n","                    (arrow_ymax >= dec_ymin and arrow_ymin <= dec_ymax)):\n","\n","                    # Recursively find the final destination shape for this arrow\n","                    destination_shape, destination_coordinates = find_final_destination(arrow_coords, set())\n","\n","                    # Determine if the arrow is labeled 'yes' or 'no'\n","                    label = label_arrow(arrow_coords)\n","\n","                    connected_arrows_destinations.append((arrow_coords, destination_shape, destination_coordinates, label))\n","\n","        # Identify and remove the arrow connected from the top\n","        top_arrow = None\n","        for arrow, _, _, _ in connected_arrows_destinations:\n","            if abs(dec_ymin - arrow['ymax']) <= 15:  # Adjust the tolerance as needed\n","                top_arrow = arrow\n","                break\n","\n","        # Remove the top-connected arrow if found\n","        if top_arrow:\n","            connected_arrows_destinations = [ad for ad in connected_arrows_destinations if ad[0] != top_arrow]\n","\n","        # If fewer than two connected arrows are found, find nearest process shapes below or at the same level\n","        if len(connected_arrows_destinations) < 2:\n","            nearest_processes = find_nearest_processes_below_or_same_level(decision_coordinates)\n","            additional_processes_needed = 2 - len(connected_arrows_destinations)\n","\n","            # Add the nearest processes below or at the same level until we have two connections\n","            for i, (shape, coords) in enumerate(nearest_processes[:additional_processes_needed]):\n","                label = 'yes' if i == 0 else 'no'  # Assign 'yes' to the nearest, 'no' to others\n","                connected_arrows_destinations.append((None, shape, coords, label))\n","\n","        # Store the connected arrows and their destinations for the current decision block\n","        decisions_and_arrows_destinations[tuple(decision_coordinates.values())] = connected_arrows_destinations\n","\n","    # Return the dictionary containing coordinates of decision blocks and their connected arrows and destinations\n","    return decisions_and_arrows_destinations\n"],"metadata":{"id":"wQIgW1dnjKEZ","executionInfo":{"status":"ok","timestamp":1719335482484,"user_tz":-330,"elapsed":868,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# def print_connections(connections_dict):\n","#     for decision_coords, connected_arrows_destinations in connections_dict.items():\n","#         print(f\"Decision block coordinates: {decision_coords}\")\n","\n","#         for arrow_coords, destination_shape, destination_coordinates, label in connected_arrows_destinations:\n","#             print(f\"  Arrow coordinates: {arrow_coords}\")\n","#             print(f\"  Destination shape: {destination_shape}\")\n","#             print(f\"  Destination coordinates: {destination_coordinates}\")\n","#             print(f\"  Label: {label}\")\n","#             print()\n","\n","#         print(\"-----------------------\")\n","# connections_dict = get_connected_arrows_and_destinations(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates)\n","\n","# # Print the connections\n","print_connections(connections_dict)"],"metadata":{"id":"a1UUcEVHZEw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_output(decision_arrows_destinations):\n","    formatted_output = []\n","\n","    for decision, arrows_dest in decision_arrows_destinations.items():\n","        decision_entry = {}\n","        decision_entry['Decision'] = decision\n","\n","        # Initialize lists for if_correct and if_wrong shapes\n","        if_correct_shapes = []\n","        if_wrong_shapes = []\n","\n","        for arrow_coords, destination_shape, destination_coords, label in arrows_dest:\n","            if label == 'yes':\n","                if_correct_shapes.append(destination_coords)\n","            elif label == 'no':\n","                if_wrong_shapes.append(destination_coords)\n","\n","        # Handle cases where only one of if_correct or if_wrong is found\n","        if if_correct_shapes and not if_wrong_shapes:\n","            # Find the nearest shape to assign as if_wrong\n","            nearest_shape = find_nearest_shape(decision, if_correct_shapes[0], decision_arrows_destinations)\n","            if_wrong_shapes.append(nearest_shape)\n","        elif if_wrong_shapes and not if_correct_shapes:\n","            # Find the nearest shape to assign as if_correct\n","            nearest_shape = find_nearest_shape(decision, if_wrong_shapes[0], decision_arrows_destinations)\n","            if_correct_shapes.append(nearest_shape)\n","        elif not if_correct_shapes and not if_wrong_shapes:\n","            # Find a process shape below the decision to assign as if_correct and a nearby shape as if_wrong\n","            if_correct_shape = find_below_shape(decision, decision_arrows_destinations)\n","            if_wrong_shape = find_nearest_shape(decision, if_correct_shape, decision_arrows_destinations, exclude=[if_correct_shape])\n","            if_correct_shapes.append(if_correct_shape)\n","            if_wrong_shapes.append(if_wrong_shape)\n","\n","        # Add if_correct and if_wrong entries if they exist\n","        if if_correct_shapes:\n","            decision_entry['if_correct'] = if_correct_shapes\n","        if if_wrong_shapes:\n","            decision_entry['if_wrong'] = if_wrong_shapes\n","\n","        formatted_output.append(decision_entry)\n","\n","    return formatted_output\n","\n","def find_nearest_shape(decision, reference_shape, decision_arrows_destinations, exclude=[]):\n","    \"\"\"\n","    Find the nearest shape to the reference_shape coordinates that is not in the exclude list.\n","    \"\"\"\n","    nearest_shape = None\n","    min_distance = float('inf')\n","\n","    ref_xmin = reference_shape['xmin']\n","    ref_ymin = reference_shape['ymin']\n","    ref_xmax = reference_shape['xmax']\n","    ref_ymax = reference_shape['ymax']\n","\n","    for _, arrows_dest in decision_arrows_destinations.items():\n","        for _, destination_shape, destination_coords, _ in arrows_dest:\n","            if destination_coords not in exclude:\n","                dest_xmin = destination_coords['xmin']\n","                dest_ymin = destination_coords['ymin']\n","                dest_xmax = destination_coords['xmax']\n","                dest_ymax = destination_coords['ymax']\n","\n","                # Calculate the Euclidean distance\n","                distance = ((ref_xmin - dest_xmin) ** 2 + (ref_ymin - dest_ymin) ** 2) ** 0.5\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    nearest_shape = destination_coords\n","\n","    return nearest_shape\n","\n","def find_below_shape(decision, decision_arrows_destinations):\n","    \"\"\"\n","    Find a shape below the decision block coordinates.\n","    \"\"\"\n","    dec_xmin = decision['xmin']\n","    dec_ymin = decision['ymin']\n","    dec_xmax = decision['xmax']\n","    dec_ymax = decision['ymax']\n","\n","    nearest_below_shape = None\n","    min_vertical_distance = float('inf')\n","\n","    for _, arrows_dest in decision_arrows_destinations.items():\n","        for _, destination_shape, destination_coords, _ in arrows_dest:\n","            dest_xmin = destination_coords['xmin']\n","            dest_ymin = destination_coords['ymin']\n","            dest_xmax = destination_coords['xmax']\n","            dest_ymax = destination_coords['ymax']\n","\n","            # Check if the shape is below the decision block\n","            if dest_ymin > dec_ymax:\n","                vertical_distance = dest_ymin - dec_ymax\n","                if vertical_distance < min_vertical_distance:\n","                    min_vertical_distance = vertical_distance\n","                    nearest_below_shape = destination_coords\n","\n","    return nearest_below_shape\n"],"metadata":{"id":"X9DVQ2KUjNFA","executionInfo":{"status":"ok","timestamp":1719335496603,"user_tz":-330,"elapsed":501,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def generate_pseudocode(flowchart):\n","    \"\"\"\n","    Generate pseudocode from the flowchart shapes.\n","    Expects a list of lists with each sublist containing [shape_name, coordinates, texts].\n","    \"\"\"\n","    pseudocode = []\n","\n","    # Extract the start shape\n","    start_shape = next((shape for shape in flowchart if shape[0] == 'Start'), None)\n","    if start_shape:\n","        start_text = ' '.join(start_shape[2])\n","        pseudocode.append(f\"Start: {start_text}\")\n","\n","    # Extract process shapes\n","    process_shapes = [shape for shape in flowchart if shape[0].startswith('Process')]\n","\n","    # Check if there's a decision block\n","    decision_shape = next((shape for shape in flowchart if shape[0] == 'decision'), None)\n","\n","    if decision_shape:\n","        # Specific method for decision-based flowchart\n","        # Extract the first process shape\n","        input_shape = next((shape for shape in process_shapes if 'input' in shape[2]), None)\n","        if input_shape:\n","            input_texts = ' '.join(input_shape[2])\n","            pseudocode.append(f\"Input: {input_texts}\")\n","\n","        # Extract the decision shape\n","        decision_texts = ' '.join(decision_shape[2])\n","        pseudocode.append(f\"Decision: {decision_texts}\")\n","\n","        # Extract processes following the decision\n","        process_correct = next((shape for shape in flowchart if shape[0] == 'Process if_correct'), None)\n","        if process_correct:\n","            process_correct_texts = ' '.join(process_correct[2])\n","            pseudocode.append(f\"       if correct:\\n            {process_correct_texts}\")\n","\n","        process_wrong = next((shape for shape in flowchart if shape[0] == 'Process if_wrong'), None)\n","        if process_wrong:\n","            process_wrong_texts = ' '.join(process_wrong[2])\n","            pseudocode.append(f\"       else:\\n            {process_wrong_texts}\")\n","\n","    else:\n","        # No decision block logic\n","        if len(process_shapes) == 3:\n","            # Exactly three process shapes\n","            input_shape, process_shape, output_shape = process_shapes\n","            input_texts = ' '.join(input_shape[2])\n","            process_texts = ' '.join(process_shape[2])\n","            output_texts = ' '.join(output_shape[2])\n","            pseudocode.append(f\"Input: {input_texts}\")\n","            pseudocode.append(f\"Process: {process_texts}\")\n","            pseudocode.append(f\"Output: {output_texts}\")\n","        elif len(process_shapes) > 3:\n","            # More than three process shapes\n","            for i, shape in enumerate(process_shapes, start=1):\n","                step_texts = ' '.join(shape[2])\n","                pseudocode.append(f\"Step {i}: {step_texts}\")\n","\n","    # Extract the end shape\n","    end_shape = next((shape for shape in flowchart if shape[0] == 'End'), None)\n","    if end_shape:\n","        end_text = ' '.join(end_shape[2])\n","        pseudocode.append(f\"End: {end_text}\")\n","\n","    return '\\n'.join(pseudocode)\n","\n","\n"],"metadata":{"id":"WhVuR_kSjQTT","executionInfo":{"status":"ok","timestamp":1719335499703,"user_tz":-330,"elapsed":2,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def coords_to_tuple(coords):\n","    if coords is None:\n","        print(\"Warning: Attempted to convert None to tuple.\")\n","        return None\n","    return (coords['xmin'], coords['ymin'], coords['xmax'], coords['ymax'])\n","\n","def process_flowchart_and_generate_pseudocode(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates):\n","    \"\"\"\n","    Main function to process the flowchart and generate pseudocode.\n","    It manages the flowchart shape identification, connection, and pseudocode generation.\n","    \"\"\"\n","\n","    # Step 1: Map texts to shapes\n","    shapes = map_text_to_shapes(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates)\n","\n","    # Step 2: Check for decision blocks\n","    decision_indices = [i for i, shape in enumerate(detected_shapes) if shape == 'decision']\n","\n","    if decision_indices:\n","        # Step 3: Process connections and update shapes if there are decision blocks\n","        connections_dict = get_connected_arrows_and_destinations(\n","            corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates\n","        )\n","\n","        formatted_output = format_output(connections_dict)\n","\n","        if formatted_output:  # Check if formatted_output is valid\n","            for decision_outcome in formatted_output:\n","                if_correct = decision_outcome.get(\"if_correct\", [])\n","                if_wrong = decision_outcome.get(\"if_wrong\", [])\n","\n","                for shape in shapes:\n","                    shape_coords = coords_to_tuple(shape[1])\n","\n","                    if shape_coords is None:\n","                        continue  # Skip updating if shape_coords is None\n","\n","                    # Update shape based on if_correct coordinates\n","                    if if_correct:\n","                        for correct in if_correct:\n","                            if shape_coords == coords_to_tuple(correct):\n","                                shape[0] = \"Process if_correct\"\n","\n","                    # Update shape based on if_wrong coordinates\n","                    if if_wrong:\n","                        for wrong in if_wrong:\n","                            if shape_coords == coords_to_tuple(wrong):\n","                                shape[0] = \"Process if_wrong\"\n","        else:\n","            print(\"Model can't clearly identify the if-else process inside the flowchart.\")\n","    else:\n","        # No decision blocks found\n","        print(\"--No decision blocks found. Proceeding with regular pseudocode generation.\")\n","\n","    # Output updated shapes (debugging)\n","    for shape in shapes:\n","        print(shape)\n","\n","    # Step 4: Generate pseudocode regardless of the presence of decision blocks\n","    pseudocode = generate_pseudocode(shapes)\n","    return pseudocode\n","\n","# Example input data (replace with actual data)\n","corrected_texts = cr_text\n","extracted_coordinates = ex_co\n","detected_shapes = ex_shape\n","shape_coordinates = ex_coor\n","\n","# Generate and print pseudocode\n","pseudocode = process_flowchart_and_generate_pseudocode(corrected_texts, extracted_coordinates, detected_shapes, shape_coordinates)\n","print(\"\\n\")\n","print(\"\\033[1mThe Generated Pseudocode from the Given Flow Chart Image is:\\033[0m\")\n","print(pseudocode)\n"],"metadata":{"id":"tMAI4iA_hz6w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719335963422,"user_tz":-330,"elapsed":552,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"879a93f4-99ac-46cb-aa8b-0aae2be457d2"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["['Start', {'xmin': 39, 'ymin': 6, 'xmax': 150, 'ymax': 63}, ['start']]\n","['Process 1', {'xmin': 0, 'ymin': 96, 'xmax': 188, 'ymax': 169}, []]\n","['decision', {'xmin': 23, 'ymin': 193, 'xmax': 166, 'ymax': 316}, ['is', 'number', 'a', 'be']]\n","['Process if_wrong', {'xmin': 202, 'ymin': 345, 'xmax': 338, 'ymax': 419}, ['output', 'odd']]\n","['Process if_correct', {'xmin': 17, 'ymin': 346, 'xmax': 172, 'ymax': 419}, ['output', 'even']]\n","['End', {'xmin': 39, 'ymin': 437, 'xmax': 147, 'ymax': 493}, ['end']]\n","\n","\n","\u001b[1mThe Generated Pseudocode from the Given Flow Chart Image is:\u001b[0m\n","Start: start\n","Decision: is number a be\n","       if correct:\n","            output even\n","       else:\n","            output odd\n","End: end\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"dGq2He7iWy6p"},"execution_count":null,"outputs":[]}]}