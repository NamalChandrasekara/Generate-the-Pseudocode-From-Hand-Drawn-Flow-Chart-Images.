{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1993NFCj_DxRk00lDEm7CJ4bydYhidNIw","timestamp":1718959302985}],"gpuType":"T4","authorship_tag":"ABX9TyPsWjH6UMQeInGaJ//sQItk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7YBdSVLTygP","executionInfo":{"status":"ok","timestamp":1717572923908,"user_tz":-330,"elapsed":34473,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"61e0f3bf-2095-43ee-d814-098fa56d0c6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms.functional as F\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# Define the label map\n","label_map = {\n","    \"arrow_line_down\": 1,\n","    \"decision\": 2,\n","    \"process\": 3,\n","    \"start_end\": 4,\n","    \"arrow_line_left\": 5,\n","    \"arrow_line_right\": 6,\n","    \"arrow_line_up\":8,\n","    \"print\":9,\n","    \"scan\": 7  # Add all other unique labels you found here\n","}\n","reverse_label_map = {v: k for k, v in label_map.items()}\n","\n","# Load the pre-trained model\n","num_classes = len(label_map) + 1  # Include background as class 0\n","model = fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n","\n","# Get the number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# Replace the pre-trained head with a new one (number of classes is the number of unique labels in your dataset + background)\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the trained model weights\n","model.load_state_dict(torch.load('/content/drive/MyDrive/faster_rcnn_flowchart.pth'))\n","model.eval()\n","\n","# Move model to the device\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","# Preprocess the image\n","def preprocess_image(image_path):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    img_tensor = F.to_tensor(img)\n","    return img_tensor\n","\n","# Postprocess the output\n","def postprocess_output(prediction, threshold=0.5):\n","    boxes = prediction[0]['boxes']\n","    labels = prediction[0]['labels']\n","    scores = prediction[0]['scores']\n","\n","    # Filter out low confidence predictions\n","    boxes = boxes[scores > threshold]\n","    labels = labels[scores > threshold]\n","    scores = scores[scores > threshold]\n","\n","    return boxes, labels, scores\n","\n","# Test the model on a single image\n","image_path = '/content/drive/MyDrive/4107.jpg'\n","img_tensor = preprocess_image(image_path)\n","img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","\n","# Move the image tensor to the device\n","img_tensor = img_tensor.to(device)\n","\n","# Get predictions\n","with torch.no_grad():\n","    prediction = model(img_tensor)\n","\n","# Postprocess the output\n","boxes, labels, scores = postprocess_output(prediction, threshold=0.5)\n","\n","# Move boxes and labels to the CPU\n","boxes = boxes.cpu()\n","labels = labels.cpu()\n","\n","# Output the shapes with their coordinates\n","def output_shapes_and_coordinates(boxes, labels, reverse_label_map):\n","    shapes = []\n","    for i in range(len(boxes)):\n","        box = boxes[i].numpy()\n","        label = labels[i].item()\n","        shapes.append({\n","            \"shape\": reverse_label_map[label],\n","            \"coordinates\": {\n","                \"xmin\": int(box[0]),\n","                \"ymin\": int(box[1]),\n","                \"xmax\": int(box[2]),\n","                \"ymax\": int(box[3])\n","            }\n","        })\n","    return shapes\n","\n","shapes = output_shapes_and_coordinates(boxes, labels, reverse_label_map)\n","\n","# Print the shapes and their coordinates\n","for shape in shapes:\n","    print(f\"Shape: {shape['shape']}, Coordinates: {shape['coordinates']}\")\n","\n","# Optionally visualize the results\n","# def visualize_results(image_path, boxes, labels, reverse_label_map):\n","#     img = Image.open(image_path).convert(\"RGB\")\n","#     plt.figure(figsize=(12, 12))\n","#     plt.imshow(img)\n","#     ax = plt.gca()\n","\n","#     for i in range(len(boxes)):\n","#         box = boxes[i].numpy()\n","#         label = labels[i].item()\n","#         color = 'r'\n","#         rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=2, edgecolor=color, facecolor='none')\n","#         ax.add_patch(rect)\n","#         plt.text(box[0], box[1], reverse_label_map[label], color=color, fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))\n","\n","#     plt.show()\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","def visualize_results(image_path, boxes, labels, reverse_label_map):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    plt.figure(figsize=(12, 12))\n","    plt.imshow(img)\n","    ax = plt.gca()\n","\n","    for i in range(len(boxes)):\n","        box = boxes[i].numpy()\n","        label = labels[i].item()\n","\n","        # Skip boxes with label \"process\"\n","        if reverse_label_map[label] == \"process\":\n","            continue\n","\n","        color = 'r'\n","        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=2, edgecolor=color, facecolor='none')\n","        ax.add_patch(rect)\n","        plt.text(box[0], box[1], reverse_label_map[label], color=color, fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))\n","\n","    plt.show()\n","\n","# Example usage:\n","# Assuming you have defined image_path, boxes, labels, and reverse_label_map appropriately\n","# visualize_results(image_path, boxes, labels, reverse_label_map)\n","\n","\n","visualize_results(image_path, boxes, labels, reverse_label_map)\n"],"metadata":{"id":"bhxc9oD8Oqa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms.functional as F\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# Define the label map\n","label_map = {\n","    \"arrow_line_down\": 1,\n","    \"decision\": 2,\n","    \"process\": 3,\n","    \"start_end\": 4,\n","    \"arrow_line_left\": 5,\n","    \"arrow_line_right\": 6,\n","    \"arrow_line_up\": 8,\n","    \"print\": 9,\n","    \"scan\": 7  # Add all other unique labels you found here\n","}\n","reverse_label_map = {v: k for k, v in label_map.items()}\n","\n","# Load the pre-trained model\n","num_classes = len(label_map) + 1  # Include background as class 0\n","model = fasterrcnn_resnet50_fpn(pretrained=True)\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the trained model weights\n","model.load_state_dict(torch.load('/content/drive/MyDrive/faster_rcnn_flowchart.pth', map_location=torch.device('cpu')))  # Update the path\n","model.eval()\n","\n","# Move model to the device\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","# Preprocess the image\n","def preprocess_image(image_path):\n","    img = Image.open(image_path).convert(\"RGB\")\n","    img_tensor = F.to_tensor(img)\n","    return img_tensor\n","\n","# Postprocess the output\n","def postprocess_output(prediction, threshold=0.5):\n","    boxes = prediction[0]['boxes']\n","    labels = prediction[0]['labels']\n","    scores = prediction[0]['scores']\n","\n","    # Filter out low confidence predictions\n","    boxes = boxes[scores > threshold]\n","    labels = labels[scores > threshold]\n","\n","    return boxes, labels\n","\n","# Function to perform inference and extract shapes and coordinates\n","def detect_shapes(image_path):\n","    # Preprocess the image\n","    img_tensor = preprocess_image(image_path)\n","    img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","    img_tensor = img_tensor.to(device)\n","\n","    # Get predictions\n","    with torch.no_grad():\n","        prediction = model(img_tensor)\n","\n","    # Postprocess the output\n","    boxes, labels = postprocess_output(prediction, threshold=0.5)\n","    boxes = boxes.cpu()\n","    labels = labels.cpu()\n","\n","    # Output the shapes with their coordinates\n","    ex_shape = []\n","    ex_coor = []\n","\n","    for i in range(len(boxes)):\n","        box = boxes[i].numpy()\n","        label = labels[i].item()\n","        shape_name = reverse_label_map[label]\n","        coordinates = {\n","            \"xmin\": int(box[0]),\n","            \"ymin\": int(box[1]),\n","            \"xmax\": int(box[2]),\n","            \"ymax\": int(box[3])\n","        }\n","        ex_shape.append(shape_name)\n","        ex_coor.append(coordinates)\n","\n","    return ex_shape, ex_coor\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWAgjWNEZGZI","executionInfo":{"status":"ok","timestamp":1717574117034,"user_tz":-330,"elapsed":1251,"user":{"displayName":"Namal Chandrasekara","userId":"14494398005576780730"}},"outputId":"b9cfdb2c-3985-49c4-b438-a0e3b507e901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Detected Shapes: ['start_end', 'start_end', 'arrow_line_down', 'arrow_line_down', 'arrow_line_down', 'arrow_line_down', 'decision', 'process', 'arrow_line_left', 'scan', 'scan', 'arrow_line_down', 'process', 'scan', 'arrow_line_right']\n","Coordinates for Shapes: [{'xmin': 39, 'ymin': 6, 'xmax': 150, 'ymax': 63}, {'xmin': 39, 'ymin': 437, 'xmax': 147, 'ymax': 493}, {'xmin': 88, 'ymin': 410, 'xmax': 102, 'ymax': 439}, {'xmin': 88, 'ymin': 159, 'xmax': 102, 'ymax': 200}, {'xmin': 88, 'ymin': 309, 'xmax': 103, 'ymax': 350}, {'xmin': 88, 'ymin': 59, 'xmax': 102, 'ymax': 100}, {'xmin': 23, 'ymin': 193, 'xmax': 166, 'ymax': 316}, {'xmin': 72, 'ymin': 128, 'xmax': 121, 'ymax': 144}, {'xmin': 146, 'ymin': 459, 'xmax': 269, 'ymax': 471}, {'xmin': 202, 'ymin': 345, 'xmax': 338, 'ymax': 419}, {'xmin': 17, 'ymin': 346, 'xmax': 172, 'ymax': 419}, {'xmin': 263, 'ymin': 258, 'xmax': 278, 'ymax': 353}, {'xmin': 16, 'ymin': 97, 'xmax': 180, 'ymax': 165}, {'xmin': 0, 'ymin': 96, 'xmax': 188, 'ymax': 169}, {'xmin': 161, 'ymin': 248, 'xmax': 274, 'ymax': 260}]\n"]}]}]}